package npmvuln.jobs

import java.sql.Timestamp

import org.threeten.extra.Interval
import com.github.gundy.semver4j.SemVer
import org.apache.spark.sql.{DataFrame, UserDefinedFunction}
import org.apache.spark.sql.functions.{col, lit, max, min, udf}

object VulnerabilityScan2 {
  val checkConstraint: UserDefinedFunction = udf[Boolean, String, String]((version, constraint) => {
    SemVer.satisfies(version, constraint)
  })

  val checkDateOverlaps: UserDefinedFunction = udf[Boolean, Timestamp, Timestamp, Timestamp, Timestamp](
    (start1, end1, start2, end2) => {
      val interval1: Interval = Interval.of(start1.toInstant, end1.toInstant)
      val interval2: Interval = Interval.of(start2.toInstant, end2.toInstant)

      interval1.overlaps(interval2)
    }
  )

  val intersectDateStart: UserDefinedFunction = udf[Timestamp, Timestamp, Timestamp, Timestamp, Timestamp](
    (start1, end1, start2, end2) => {
      val interval1: Interval = Interval.of(start1.toInstant, end1.toInstant)
      val interval2: Interval = Interval.of(start2.toInstant, end2.toInstant)

      Timestamp.from(interval1.intersection(interval2).getStart)
    }
  )

  val intersectDateEnd: UserDefinedFunction = udf[Timestamp, Timestamp, Timestamp, Timestamp, Timestamp](
    (start1, end1, start2, end2) => {
      val interval1: Interval = Interval.of(start1.toInstant, end1.toInstant)
      val interval2: Interval = Interval.of(start2.toInstant, end2.toInstant)

      Timestamp.from(interval1.intersection(interval2).getEnd)
    }
  )


  def recurse(cReleasesDf: DataFrame, vulnDf: DataFrame, maxLevel: Int = Int.MaxValue, level: Int = 0): DataFrame = {
    val hasDownstream: Boolean = vulnDf.filter(col("Level") === level)
      .join(cReleasesDf, vulnDf("Project") === cReleasesDf("Dependency"))
      .count > 0

    if (hasDownstream && level < maxLevel){
      val currentIterVuln: DataFrame = vulnDf
        .join(cReleasesDf, vulnDf("Project") === cReleasesDf("Dependency")
          && checkConstraint(vulnDf("Release"), cReleasesDf("Constraint")))
        .filter(checkDateOverlaps(col("StartDate"), col("EndDate"), col("Date"), col("NextReleaseDate")))
        .withColumn("StartDate", intersectDateStart(col("StartDate"), col("EndDate"), col("Date"), col("NextReleaseDate")))
        .withColumn("EndDate", intersectDateEnd(col("StartDate"), col("EndDate"), col("Date"), col("NextReleaseDate")))
        .withColumn("Project", col("Package"))
        .withColumn("Release", col("Version"))
        .groupBy("Id", "Project", "Release", "Name", "Severity")
        .agg(min("StartDate").as("StartDate"), max("EndDate").as("EndDate"))
        .withColumn("Level", lit(level + 1))
        .select("Id", "Project", "Release", "Name", "Severity", "StartDate", "EndDate", "Level")

      recurse(cReleasesDf, vulnDf.unionAll(currentIterVuln), maxLevel, level + 1)
    } else {
      vulnDf
    }
  }

  def run(releasesDf: DataFrame, dependenciesDf: DataFrame, advisoryDf: DataFrame, maxLevel: Int): DataFrame = {
    // Package, Version, Date, NextReleaseDate, Dependency, Constraint
    val completeReleasesDf: DataFrame = releasesDf
      .join(dependenciesDf, Seq("Project", "Release"))
      .withColumnRenamed("Project", "Package")
      .withColumnRenamed("Release", "Version")

    // Id, Project, Release, StartDate, EndDate, Level
    val vulnDf: DataFrame = advisoryDf
      .join(releasesDf, advisoryDf("Package") === releasesDf("Project")
        && checkConstraint(releasesDf("Release"), advisoryDf("Versions")))
      .select("Id", "Project", "Release", "Name", "Severity", "Date", "NextReleaseDate")
      .withColumn("Level", lit(0))
      .withColumnRenamed("Date", "StartDate")
      .withColumnRenamed("NextReleaseDate", "EndDate")

    recurse(completeReleasesDf, vulnDf, maxLevel)
  }
}
